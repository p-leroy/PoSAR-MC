{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/pleroy/DEV/processing/PoSAR-MC\")\n",
    "from posarmctools.readdata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/pleroy/DEV/processing/focalization_python\")\n",
    "from posarutils.other.read_data_and_build_rd import *\n",
    "from posarutils.other.PosarMCParameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_date = \"2018_05_18_14_32_30\"\n",
    "data_dir = \"/home/pleroy/DATA/PoSAR-v2_PIMA_TEST-3/2018_05_18/\" + data_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_filename = data_dir + \"/\" + data_date + \"_parameters.xml\"\n",
    "params = PosarMCParameters_v2( params_filename )\n",
    "params.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffersPerFile = params.buffersPerFile\n",
    "samplesPerRamp = params.samplesPerRamp\n",
    "rampsPerFile = params.rampsPerFile\n",
    "samplesPerFile = samplesPerRamp * rampsPerFile\n",
    "\n",
    "print( \"buffersPerFile = {}, samplesPerRamp = {}, rampsPerFile = {}\".format(\n",
    "    buffersPerFile, samplesPerRamp, rampsPerFile )\n",
    "     )\n",
    "\n",
    "# selection in record\n",
    "firstFile = 82\n",
    "nbFiles = 75\n",
    "lastFile = firstFile + nbFiles - 1\n",
    "firstBuffer = firstFile * buffersPerFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalingFactor = 2 / 65535\n",
    "offset = -32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSerie_A = np.zeros( samplesPerFile )\n",
    "adc_A = np.zeros( (nbFiles, samplesPerFile) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_A_a = np.zeros( samplesPerFile )\n",
    "adc_A_b = np.zeros( samplesPerFile )\n",
    "\n",
    "idxFirst = firstFile\n",
    "idxLast = lastFile\n",
    "idxFirst = 0\n",
    "idxLast = 100\n",
    "\n",
    "filename = data_dir + \"/record\" + str(idxFirst) + \".bin\"\n",
    "readFileADLINKCh0( filename, samplesPerFile, timeSerie_A )   \n",
    "adc_A_a[ : ] = (timeSerie_A + offset) * scalingFactor\n",
    "\n",
    "filename = data_dir + \"/record\" + str(idxLast) + \".bin\"\n",
    "readFileADLINKCh0( filename, samplesPerFile, timeSerie_A )   \n",
    "adc_A_b[ : ] = (timeSerie_A + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSerie_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(adc_A_a[0:12000], label='adc_A, record {}'.format(idxFirst))\n",
    "plt.plot(adc_A_a[-12000:], label='adc_A end, record {}'.format(idxFirst))\n",
    "plt.plot(adc_A_b[0:12000], label='adc_A, record {}'.format(idxLast))\n",
    "plt.plot(adc_A_b[-12000:], label='adc_A end, record {}'.format(idxLast))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(data_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( 20 * np.log10( np.abs( np.fft.fft( adc_A_a[0:6000] ) ) ), label='adc_A_a' )\n",
    "plt.plot( 20 * np.log10( np.abs( np.fft.fft( adc_A_b[0:6000] ) ) ), label='adc_A_b' )\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = data_dir + \"/record\" + str(idxFirst) + \".bin\"\n",
    "fd = open(filename,'rb')\n",
    "time_series_a = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor\n",
    "\n",
    "filename = data_dir + \"/record\" + str(idxLast) + \".bin\"\n",
    "fd = open(filename,'rb')\n",
    "time_series_b = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_series_a[0:12000], '.', label='adc_A_a')\n",
    "plt.plot(adc_A_a[12000:24000], label='adc_A_a alt')\n",
    "plt.plot(time_series_b[0:12000], label='adc_A_b')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#360\n",
    "time_series = np.zeros( (37,samplesPerRamp))\n",
    "\n",
    "for k in range(0, 37):\n",
    "    filename = data_dir + \"/record\" + str(k*10) + \".bin\"\n",
    "    fd = open(filename,'rb')\n",
    "    time_series_a = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor\n",
    "    time_series[k, :] = time_series_a[0:samplesPerRamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 10):\n",
    "    plt.plot(time_series[k, :], label=\"{}\".format(k))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.figure()\n",
    "for k in range(10, 20):\n",
    "    plt.plot(time_series[k, :], label=\"{}\".format(k))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.figure()\n",
    "for k in range(20, 30):\n",
    "    plt.plot(time_series[k, :], label=\"{}\".format(k))\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for perturbated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nbFiles-1) * buffersPerFile + firstBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = data_dir + \"/record312.bin\"\n",
    "fd = open(filename,'rb')\n",
    "time_series_a = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 100, 10):\n",
    "    plt.plot( time_series_a[ k*params.samplesPerRamp : params.samplesPerRamp*(k+1) ] )\n",
    "plt.grid()\n",
    "plt.title(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 100, 10):\n",
    "    plt.plot( 20 * np.log10( np.abs( np.fft.fft( time_series_a[ k*params.samplesPerRamp : params.samplesPerRamp*(k+1) ] ) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastBuffer = (nbFiles-1) * buffersPerFile + firstBuffer\n",
    "for k in range( nbFiles ):\n",
    "    \n",
    "    # read the data\n",
    "    nb = str( int( k * buffersPerFile + firstBuffer) )\n",
    "    filename = data_dir + \"/record\" + nb + \".bin\"\n",
    "    readFileADLINKCh0( filename, samplesPerFile, timeSerie_A )\n",
    "    \n",
    "    print(\"k = {}, block = {} / {}\".format(k, nb, lastBuffer))\n",
    "    \n",
    "    adc_A[ k, : ] = (timeSerie_A + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_reshaped = adc_A.reshape(nbFiles * rampsPerFile, samplesPerRamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the first ramp is an up ramp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( A_reshaped[0, :] )\n",
    "plt.title(\"first acquisition\\n\" + data_date)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the shifted flag properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rampDownFirst = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesPerDownRamp = int(samplesPerRamp/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs = 20 * np.log10( np.abs( fft_A ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs[::100, 0:1000], cmap='gray' )\n",
    "title = \"no window \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming = np.hamming(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_hamming = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*hamming, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_hamming = 20 * np.log10( np.abs( fft_A_hamming ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_hamming[::100, 0:1000], cmap='gray' )\n",
    "title = \"hamming \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanning = np.hanning(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_hanning = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*hanning, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_hanning = 20 * np.log10( np.abs( fft_A_hanning ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_hanning[::100, 0:1000], cmap='gray' )\n",
    "title = \"hanning \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackman (peu utilisée, cf lff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackman = np.blackman(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_blackman = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*blackman, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_blackman = 20 * np.log10( np.abs( fft_A_blackman ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_blackman[::100, 0:1000], cmap='gray' )\n",
    "title = \"blackman \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta Window shape\n",
    "# 0    Rectangular\n",
    "# 5    Similar to a Hamming\n",
    "# 6    Similar to a Hanning\n",
    "# 8.6  Similar to a Blackman\n",
    "# kaiser = np.kaiser(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_kaiser = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*kaiser, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_kaiser = 20 * np.log10( np.abs( fft_A_kaiser ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_kaiser[::100, 0:1000], cmap='gray' )\n",
    "plt.title(\"kaiser \" + data_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RDc = build_rd_from_data( params, A_reshaped, shifted )\n",
    "withHanning = 1\n",
    "RDc = build_rd_from_data_rampDown( params, A_reshaped, rampDownFirst, withHanning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_RD = np.average(RDc, 0)\n",
    "np.save( data_dir + \"/coupling_RD_files_{}_{}_rampDown_hanning\".format(firstFile, lastFile), coupling_RD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.abs(coupling_RD), 'k', label='coupling')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if withHanning:\n",
    "    np.save(data_dir + '/RD_files_{}_{}_rampDown_hanning'.format(firstFile, lastFile), RDc) \n",
    "else:\n",
    "    np.save(data_dir + '/RD_files_{}_{}_rampDown'.format(firstFile, lastFile), RDc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
