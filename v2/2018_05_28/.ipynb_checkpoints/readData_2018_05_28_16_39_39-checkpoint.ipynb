{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/pleroy/DEV/processing/PoSAR-MC\")\n",
    "from posarmctools.readdata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/pleroy/DEV/processing/focalization_python\")\n",
    "from posarutils.other.read_data_and_build_rd import *\n",
    "from posarutils.other.PosarMCParameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_date = \"2018_05_28_13_33_00\"\n",
    "data_dir = \"/home/pleroy/DATA/PoSAR-v2_PIMA_TEST-3/2018_05_28/\" + data_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requestedTRamp 1200.0\n",
      "configuredTRamp 1200.0\n",
      "startFrequency 5725000000.0\n",
      "stopFrequency 5875000000.0\n",
      "frequencyBand 150000000.0\n",
      "frequencyDevReq 50000.0\n",
      "frequencyDevConf 50001.1\n",
      "numberOfSteps 3000\n",
      "waveformType 1\n",
      "rampsPerBuffer 375\n",
      "bufferSize 9000000.0\n",
      "buffersPerFile 2\n",
      "rampsPerFile 750\n",
      "fileSize 18000000.0\n",
      "samplingFrequency 10000000.0\n",
      "samplesPerRamp 12000\n",
      "skipNSamples 0\n"
     ]
    }
   ],
   "source": [
    "params_filename = data_dir + \"/\" + data_date + \"_parameters.xml\"\n",
    "params = PosarMCParameters_v2( params_filename )\n",
    "params.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffersPerFile = 2, samplesPerRamp = 12000, rampsPerFile = 750\n"
     ]
    }
   ],
   "source": [
    "buffersPerFile = params.buffersPerFile\n",
    "samplesPerRamp = params.samplesPerRamp\n",
    "rampsPerFile = params.rampsPerFile\n",
    "samplesPerFile = samplesPerRamp * rampsPerFile\n",
    "\n",
    "print( \"buffersPerFile = {}, samplesPerRamp = {}, rampsPerFile = {}\".format(\n",
    "    buffersPerFile, samplesPerRamp, rampsPerFile )\n",
    "     )\n",
    "\n",
    "# selection in record\n",
    "firstFile = 72\n",
    "nbFiles = 78\n",
    "lastFile = firstFile + nbFiles - 1\n",
    "firstBuffer = firstFile * buffersPerFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalingFactor = 2 / 65535\n",
    "offset = -32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSerie_A = np.zeros( samplesPerFile )\n",
    "adc_A = np.zeros( (nbFiles, samplesPerFile) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_A_a = np.zeros( samplesPerFile )\n",
    "adc_A_b = np.zeros( samplesPerFile )\n",
    "\n",
    "idxFirst = firstFile\n",
    "idxLast = lastFile\n",
    "idxFirst = 0\n",
    "idxLast = 100\n",
    "\n",
    "filename = data_dir + \"/record\" + str(idxFirst) + \".bin\"\n",
    "readFileADLINKCh0( filename, samplesPerFile, timeSerie_A )   \n",
    "adc_A_a[ : ] = (timeSerie_A + offset) * scalingFactor\n",
    "\n",
    "filename = data_dir + \"/record\" + str(idxLast) + \".bin\"\n",
    "readFileADLINKCh0( filename, samplesPerFile, timeSerie_A )   \n",
    "adc_A_b[ : ] = (timeSerie_A + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSerie_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(adc_A_a[0:12000], label='adc_A, record {}'.format(idxFirst))\n",
    "plt.plot(adc_A_a[-12000:], label='adc_A end, record {}'.format(idxFirst))\n",
    "plt.plot(adc_A_b[0:12000], label='adc_A, record {}'.format(idxLast))\n",
    "plt.plot(adc_A_b[-12000:], label='adc_A end, record {}'.format(idxLast))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(data_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( 20 * np.log10( np.abs( np.fft.fft( adc_A_a[0:6000] ) ) ), label='adc_A_a' )\n",
    "plt.plot( 20 * np.log10( np.abs( np.fft.fft( adc_A_b[0:6000] ) ) ), label='adc_A_b' )\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = data_dir + \"/record\" + str(idxFirst) + \".bin\"\n",
    "fd = open(filename,'rb')\n",
    "time_series_a = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor\n",
    "\n",
    "filename = data_dir + \"/record\" + str(idxLast) + \".bin\"\n",
    "fd = open(filename,'rb')\n",
    "time_series_b = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_series_a[0:12000], '.', label='adc_A_a')\n",
    "plt.plot(adc_A_a[12000:24000], label='adc_A_a alt')\n",
    "plt.plot(time_series_b[0:12000], label='adc_A_b')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#360\n",
    "time_series = np.zeros( (37,samplesPerRamp))\n",
    "\n",
    "for k in range(0, 37):\n",
    "    filename = data_dir + \"/record\" + str(k*10) + \".bin\"\n",
    "    fd = open(filename,'rb')\n",
    "    time_series_a = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor\n",
    "    time_series[k, :] = time_series_a[0:samplesPerRamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 10):\n",
    "    plt.plot(time_series[k, :], label=\"{}\".format(k))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.figure()\n",
    "for k in range(10, 20):\n",
    "    plt.plot(time_series[k, :], label=\"{}\".format(k))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.figure()\n",
    "for k in range(20, 30):\n",
    "    plt.plot(time_series[k, :], label=\"{}\".format(k))\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for perturbated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nbFiles-1) * buffersPerFile + firstBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = data_dir + \"/record312.bin\"\n",
    "fd = open(filename,'rb')\n",
    "time_series_a = (np.fromfile(fd, dtype = np.uint16) + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 100, 10):\n",
    "    plt.plot( time_series_a[ k*params.samplesPerRamp : params.samplesPerRamp*(k+1) ] )\n",
    "plt.grid()\n",
    "plt.title(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 100, 10):\n",
    "    plt.plot( 20 * np.log10( np.abs( np.fft.fft( time_series_a[ k*params.samplesPerRamp : params.samplesPerRamp*(k+1) ] ) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0, block = 144 / 298\n",
      "k = 1, block = 146 / 298\n",
      "k = 2, block = 148 / 298\n",
      "k = 3, block = 150 / 298\n",
      "k = 4, block = 152 / 298\n",
      "k = 5, block = 154 / 298\n",
      "k = 6, block = 156 / 298\n",
      "k = 7, block = 158 / 298\n",
      "k = 8, block = 160 / 298\n",
      "k = 9, block = 162 / 298\n",
      "k = 10, block = 164 / 298\n",
      "k = 11, block = 166 / 298\n",
      "k = 12, block = 168 / 298\n",
      "k = 13, block = 170 / 298\n",
      "k = 14, block = 172 / 298\n",
      "k = 15, block = 174 / 298\n",
      "k = 16, block = 176 / 298\n",
      "k = 17, block = 178 / 298\n",
      "k = 18, block = 180 / 298\n",
      "k = 19, block = 182 / 298\n",
      "k = 20, block = 184 / 298\n",
      "k = 21, block = 186 / 298\n",
      "k = 22, block = 188 / 298\n",
      "k = 23, block = 190 / 298\n",
      "k = 24, block = 192 / 298\n",
      "k = 25, block = 194 / 298\n",
      "k = 26, block = 196 / 298\n",
      "k = 27, block = 198 / 298\n",
      "k = 28, block = 200 / 298\n",
      "k = 29, block = 202 / 298\n",
      "k = 30, block = 204 / 298\n",
      "k = 31, block = 206 / 298\n",
      "k = 32, block = 208 / 298\n",
      "k = 33, block = 210 / 298\n",
      "k = 34, block = 212 / 298\n",
      "k = 35, block = 214 / 298\n",
      "k = 36, block = 216 / 298\n",
      "k = 37, block = 218 / 298\n",
      "k = 38, block = 220 / 298\n",
      "k = 39, block = 222 / 298\n",
      "k = 40, block = 224 / 298\n",
      "k = 41, block = 226 / 298\n",
      "k = 42, block = 228 / 298\n",
      "k = 43, block = 230 / 298\n",
      "k = 44, block = 232 / 298\n",
      "k = 45, block = 234 / 298\n",
      "k = 46, block = 236 / 298\n",
      "k = 47, block = 238 / 298\n",
      "k = 48, block = 240 / 298\n",
      "k = 49, block = 242 / 298\n",
      "k = 50, block = 244 / 298\n",
      "k = 51, block = 246 / 298\n",
      "k = 52, block = 248 / 298\n",
      "k = 53, block = 250 / 298\n",
      "k = 54, block = 252 / 298\n",
      "k = 55, block = 254 / 298\n",
      "k = 56, block = 256 / 298\n",
      "k = 57, block = 258 / 298\n",
      "k = 58, block = 260 / 298\n",
      "k = 59, block = 262 / 298\n",
      "k = 60, block = 264 / 298\n",
      "k = 61, block = 266 / 298\n",
      "k = 62, block = 268 / 298\n",
      "k = 63, block = 270 / 298\n",
      "k = 64, block = 272 / 298\n",
      "k = 65, block = 274 / 298\n",
      "k = 66, block = 276 / 298\n",
      "k = 67, block = 278 / 298\n",
      "k = 68, block = 280 / 298\n",
      "k = 69, block = 282 / 298\n",
      "k = 70, block = 284 / 298\n",
      "k = 71, block = 286 / 298\n",
      "k = 72, block = 288 / 298\n",
      "k = 73, block = 290 / 298\n",
      "k = 74, block = 292 / 298\n",
      "k = 75, block = 294 / 298\n",
      "k = 76, block = 296 / 298\n",
      "k = 77, block = 298 / 298\n"
     ]
    }
   ],
   "source": [
    "lastBuffer = (nbFiles-1) * buffersPerFile + firstBuffer\n",
    "for k in range( nbFiles ):\n",
    "    \n",
    "    # read the data\n",
    "    nb = str( int( k * buffersPerFile + firstBuffer) )\n",
    "    filename = data_dir + \"/record\" + nb + \".bin\"\n",
    "    readFileADLINKCh0( filename, samplesPerFile, timeSerie_A )\n",
    "    \n",
    "    print(\"k = {}, block = {} / {}\".format(k, nb, lastBuffer))\n",
    "    \n",
    "    adc_A[ k, : ] = (timeSerie_A + offset) * scalingFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_reshaped = adc_A.reshape(nbFiles * rampsPerFile, samplesPerRamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the first ramp is an up ramp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( A_reshaped[0, :] )\n",
    "plt.title(\"first acquisition\\n\" + data_date)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the shifted flag properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rampDownFirst = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesPerDownRamp = int(samplesPerRamp/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs = 20 * np.log10( np.abs( fft_A ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs[::100, 0:1000] )\n",
    "title = \"no window \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming = np.hamming(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_hamming = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*hamming, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_hamming = 20 * np.log10( np.abs( fft_A_hamming ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_hamming[::100, 0:1000], cmap='gray' )\n",
    "title = \"hamming \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanning = np.hanning(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_hanning = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*hanning, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_hanning = 20 * np.log10( np.abs( fft_A_hanning ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_hanning[::100, 0:1000], cmap='gray' )\n",
    "title = \"hanning \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackman (peu utilisée, cf lff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackman = np.blackman(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_blackman = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*blackman, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_blackman = 20 * np.log10( np.abs( fft_A_blackman ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_blackman[::100, 0:1000], cmap='gray' )\n",
    "title = \"blackman \" + data_date\n",
    "plt.title(title)\n",
    "plt.savefig( data_dir + \"/\" + title + \".png\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta Window shape\n",
    "# 0    Rectangular\n",
    "# 5    Similar to a Hamming\n",
    "# 6    Similar to a Hanning\n",
    "# 8.6  Similar to a Blackman\n",
    "# kaiser = np.kaiser(samplesPerDownRamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_A_kaiser = np.fft.ifft(A_reshaped[:, 0:samplesPerDownRamp]*kaiser, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_abs_kaiser = 20 * np.log10( np.abs( fft_A_kaiser ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow( fft_abs_kaiser[::100, 0:1000], cmap='gray' )\n",
    "plt.title(\"kaiser \" + data_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the samples matrix = (58500, 12000)\n",
      "ramp down first in the data files\n"
     ]
    }
   ],
   "source": [
    "#RDc = build_rd_from_data( params, A_reshaped, shifted )\n",
    "withHanning = 0\n",
    "RDc = build_rd_from_data_rampDown( params, A_reshaped, rampDownFirst, withHanning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_RD = np.average(RDc, 0)\n",
    "if withHanning:\n",
    "    np.save( data_dir + \"/coupling_RD_files_{}_{}_rampDown_hanning\".format(firstFile, lastFile), coupling_RD )\n",
    "else:\n",
    "    np.save( data_dir + \"/coupling_RD_files_{}_{}_rampDown\".format(firstFile, lastFile), coupling_RD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.abs(coupling_RD), 'k', label='coupling')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if withHanning:\n",
    "    np.save(data_dir + '/RD_files_{}_{}_rampDown_hanning'.format(firstFile, lastFile), RDc) \n",
    "else:\n",
    "    np.save(data_dir + '/RD_files_{}_{}_rampDown'.format(firstFile, lastFile), RDc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
